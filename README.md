<!-- Never trust the month of April.

---

## I’m currently working on ...
- My own kernel (for educational purposes, nothing fancy). :)

- Rowland Hall's FTC Robot Software

- [This](https://www.youtube.com/watch?v=dQw4w9WgXcQ)

---
-->

# Welcome!

My humble adobe. High-school CS student. Graduating class of 2025 (drawing ever nearer; not sure how I feel about this). I prefer to use Linux but MacOS typically sufices.

Recently got into kernel hacking, loving it. I thought it would be a *lot* harder.

---

## My beliefs

<details>
<summary>The "manifesto".</summary>
<br>
As time passes and I get better at what I do, I've noticed a disturbing side effect of the "learn to code" movement. Many people think that because they can code, they're suddenly experts in everything related to computers. This is not only untrue, but it's also dangerous. I absolutely do not mean everybody, but most are content at doing what they were taught, most likely basic AI with TensorFlow/PyTorch or Front End (with the endless new frameworks that come with it). How these people go about this (which isn't their fault, it's the fault of the education they received) is not good enough as it currently stands.


### Thinking for yourself:

To make real progress in the field of computing, we need to be able to think for ourselves. We need to be able to question the status quo, explore new ideas and be unafraid of failure. We need to be able to do more than just code. This is part of the reason I dislike the term code. Not only does it perpetuate the populate misconception of unavoidable esotericism within computer science, but it also implies that it doesn't require as much thought or effort as it actually does. The word coding seems like you are encoding something. As such, you'd check it against a sheet or (most likely in today's cyber security ecosystem) run it through an algorithm. Word coding suggests that a one-to-one representation is a terrible analogy when applied to programming. Programming is about problem-solving; typing out instructions is just a formality.

The ability to think for oneself is a skill that can be learned. It's not something that you're born with. It's something that you develop over time by asking questions, exploring new ideas and by being unafraid of failure. The ability to code is not the same as the ability to think for oneself. In fact, coding is a fantastic way to develop problem-solving approaches that you can apply to any situation, even outside computing.

Groupthink is a dangerous phenomenon that can occur when a group of people get together and start to think alike. This can lead to bad decision-making and harm the individual and the group. Groupthink can be especially harmful in computer science, where new ideas and innovations are essential for progress. The best way to avoid groupthink is by encouraging individual thinking and promoting a culture of questioning and exploration. We need to be unafraid of failure, and we need to be willing to think for ourselves. We need to be able to explore new ideas and challenge the status quo. Only by doing this can we make real progress in computer science.

Take the dramatic transition between “legacy” IBM PC compatibles (BIOS + MBR) and “modern” PCs (UEFI + BLOAT + GPT). While I may not agree with most of the design decisions behind UEFI, it's still an idea that tries to solve the limiting factors of BIOS. If everyone kept going with BIOS and MBR via groupthink, large disks would have to have dramatically complex linked partition table schemes. UEFI and GPT were bold new steps that increased the user-friendliness, speed, and compatibility that were lacking in legacy BIOS systems.


### Teaching yourself, at least to a small degree:
I don't mean looking up your error messages and questions on Stack Overflow (more on this later). This means trying to learn new topics by yourself. There seems to be a great divide between the quality of computer science education today, most of it being generally subpar. I'm fortunate to have access to a great program where I go to school, but I didn't get where I am today with that. My father was a software developer, and one day a couple years back, he helped me through installing Ubuntu on a small server and emailed me an article about how to set up a Samba file server (I think it was this, not FTP) and let me fend for myself. I was only 11-12 at the time, so I obviously needed some help, but after the initial hurdle, I decided I wanted to learn more.

This, I believe, is where the quality gap diverges. On the one hand, you have the low-quality, pumped-out, *paid* online courses (learn Python in three days!). Note that by no means are all online courses bad. But most of the time, these courses give you a pretty shaky foundation. The interactivity here is extremely limited, so you can just zone out and copy down some code. You can't really learn by yourself after your sub-par course ends, and you have nowhere to go besides being into their program more. By contrast, taking a class through an educational institution (e.g. a school or university) gives you a foundation that you can use to start teaching yourself. However, being only used to a highly structured learning environment is damaging later on when you try and learn something yourself, by yourself.

This education gap is not just bad for people who don't know any better but also for people who can't afford higher quality education. Lower-income people or minorities generally have less access to quality computer science education and just quality education. Even though I am a minority myself (neurologically, sexually, and in terms of gender), I count myself lucky, obviously because of my socioeconomic stance, but also because I had access to an adequate "education" (by this, I mean emailing my father asking him questions) to kickstart my learning. I downloaded Löve2D, pulled down a tutorial (the exact one I followed), and tried to learn about functions, conditionals, and loops. Naturally, I got stuck and had to ask for a bit of help, but after a few days, I tried to recreate a simple game I found on the app store that I couldn't download.

This brings me to why I think teaching yourself (at least to a small degree) is beneficial. After I "recreated" the app (at least to the best of my 12-year-old self's skills), I realized I could create almost anything I wanted with some resourcefulness. With a loosely structured program, it's rare to get to that point, whereas in a highly structured environment, you never come across it because you are learning theory and not as much as how to apply it to things you might want to build. I've seen CS graduates who've never heard of a compiler.

Teaching yourself encourages creativity and a "figure it out" mentality. This is something that is severely lacking in many, if not most, computer science graduates. You can find it if you dig hard enough, but it's not common. I think the best way to start teaching yourself is by finding resources that interest you. This can be anything, like a particular language, library, or tool. Once you find a resource, try to find a tutorial, article, or hell, even documentation that is at a level you can understand. If you get stuck, ask a friend or post on a forum. Don't be afraid to be wrong, and be prepared to be frustrated.


### Solve your own damn problems:
What's the point of problem-solving skills if you can never apply them? If you simply copy every error and warning your face into a search engine of your choice, are you actually learning anything? Some might argue that you're doing it right as long as you're getting the desired output. I would say that you're not learning, and you're not getting better. The best way to learn is to try and solve the problem yourself. This doesn't mean you have to do it alone; it's often better to get help (experts are experts for a reason), but you should at least try to understand the problem and how to solve it.

Otherwise, in the future, you may get an error of which you cannot use Google or a symptom of a problem you can't even diagnose. In times like these, you need to have skills you learned from trying to solve the problem yourself. This also ties in with the idea of thinking for oneself. You're not thinking for yourself if you're always copying and pasting code. You're not exploring, questioning or trying new things. You're not learning. You're not getting better. You're not becoming an expert or a computer scientist. You're a code monkey.

Blindly copying and pasting from the internet/man pages/what have you is an example of groupthink, something this document (and hopefully your common sense) told you is not a good idea as it stifles innovation. You might not notice systemic problems; recognizing them is half the battle. The other half is going to fix them. If no one fixed outdated or bad systems, we'd still be stuck in the UNIVAC and ENIAC days, and maybe if we were lucky, the PDP days (from the *very* little assembly I've written for a PDP-11 emulator, it seems nice).

A well-designed and robust system is one where it forces you to evaluate your own code for safety, correctness and usability before you press it into service. If you don't have this, you're relying on others to make those calls for you. You are not, and never will be, qualified to make that call if you never take matters into your own hands. You can think of your code as code; all layers above it make it a product. You might have a vague idea of how your code fits together, but until you can look at the code you wrote and say with certainty what data it mutates and whatnot, your code, and the project as a whole, will suffer.

### Extras:
I may add more sections to the manifesto in the future if I feel like it, but here are some points worth mentioning.

1. Be creative. Computers can do amazing things, but we need to be creative to take advantage of that potential. Be creative in your thinking, in your coding and in your problem-solving.
2. Be open-minded. The world of computing is full of surprises. Be open-minded to new ideas, new technologies and new ways of doing things.
3. Be persistent. Computer science is a challenging field, and you will encounter setbacks along the way. Be persistent in your efforts, and don't give up.
4. Be humble. Nobody knows everything, and there is always more to learn. Be humble in your approach to learning and to problem-solving.
5. Be patient. Computing is a complex field, and it takes time to learn everything. Be patient in your efforts, and don't try to learn everything at once.
6. Be respectful. Computing is a global field, and we need to respect the cultures and traditions of other countries. Be respectful of other people's opinions, and be willing to learn from them.
7. Be ethical. Computing can be used for good or evil, and it is up to us to use it for the good of humanity. Be ethical in your thinking and in your actions. These principles are by no means exhaustive, but they are a good starting point for anybody who wants to be a both morally and personally successful engineer.
</details>

---

<p align="center">
    <img width=65% src="https://github-readme-stats.vercel.app/api?username=isaccbarker&show_icons=true&theme=radical">
    <img width=65% src="https://github-readme-stats.vercel.app/api/wakatime?username=isaccbarker&&hide=javascript,html,css,cmake,Nginx%20Configuration%20File,markdown,groovy,text,properties,tmux,sql,matlab,systemd,yaml,json,bc,xml,csv,ini,PacmanConf,Other,viml,Image%20%28jpeg%29,crontab,zsh,swift,objective-c,meson,protocol%20buffer,common%20lisp,arduino,conf,toml&layout=compact&theme=radical">
</p>
<!-- </p> -->
